{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đọc/ghi file Parquet trong Hadoop sử dụng mô hình MapReduce\n",
    "\n",
    "* Sử dụng thư viện Apache Spark trên EMR để tiến hành đọc file .csv từ Amazon S3 và chuyển thành file .parquet và cũng dùng chính thư viện này để tiến hành đọc/ghi file .parquet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Kiểm tra kết nối giữa Cluster của EMR và Instance của SageMaker Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Tiến hành đọc file .csv từ S3 và hiển thị kết quả, đồng thời cho biến thời gian để lấy thời gian đọc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Biến tính thời gian\n",
    "var t = System.nanoTime\n",
    "\n",
    "//Tạo biến df chứa dataframe của file .csv đọc được từ S3\n",
    "val df = spark.read.option(\"header\",true).csv(\"s3://hadoopbucket177103/input/train.csv\")\n",
    "\n",
    "//In thời gian thực thi câu lệnh trên, convert thời gian từ Nanosec sang Sec, chuyển về double\n",
    "var duration = (System.nanoTime - t) / 1e9d\n",
    "\n",
    "//In kết quả có được sau khi đọc file .csv (20 dòng đầu tiên)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Ghi Dataframe vào file .csv lưu trữ trên Amazon S3, đồng thời xác định thời gian để thực thi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = System.nanoTime\n",
    "\n",
    "//Ghi Dataframe vào file .csv\n",
    "df.write.mode(\"overwrite\").csv(\"s3://hadoopbucket177103/output/train.csv\")\n",
    "\n",
    "duration = (System.nanoTime - t) / 1e9d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Ghi Dataframe vào file .parquet lưu trữ trên Amazon S3, đồng thời xác định thời gian để thực thi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = System.nanoTime\n",
    "\n",
    "//Ghi Dataframe vào file .parquet\n",
    "df.write.mode(\"overwrite\").parquet(\"s3://hadoopbucket177103/output/train.parquet\")\n",
    "\n",
    "duration = (System.nanoTime - t) / 1e9d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Đọc file .parquet trên Amazon S3 và đưa vào Dataframe, đồng thời xác định thời gian để thực thi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = System.nanoTime\n",
    "\n",
    "//Tạo biến df2 chứa dataframe của file .parquet đọc được từ S3\n",
    "val df2 = spark.read.parquet(\"s3://hadoopbucket177103/output/train.parquet\")\n",
    "\n",
    "duration = (System.nanoTime - t) / 1e9d\n",
    "\n",
    "//Hiển thị kết quả lấy được từ file .parquet trong Dataframe\n",
    "df2.show();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Thực hiện 1 số câu query trên Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Tạo tempView để thực hiện truy vấn SQL\n",
    "df2.createOrReplaceTempView(\"ParquetTable\")\n",
    "\n",
    "//Thực hiện câu truy vấn\n",
    "t = System.nanoTime\n",
    "val parkSQL = spark.sql(\"select * from ParquetTable where user_answer > 2 \")\n",
    "duration = (System.nanoTime - t) / 1e9d\n",
    "\n",
    "//show table\n",
    "parkSQL.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Thực hiện câu truy vấn\n",
    "t = System.nanoTime\n",
    "val parkSQL = spark.sql(\"select * from ParquetTable where (prior_question_elapsed_time >= 5000) and (prior_question_elapsed_time <= 15000) \")\n",
    "duration = (System.nanoTime - t) / 1e9d\n",
    "\n",
    "//show table\n",
    "parkSQL.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e4bab93dda6eb48e260000208dd1da45680b605ccb4f5ae7db320d096721fe0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
